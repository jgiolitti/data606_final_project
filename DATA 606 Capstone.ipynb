{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad3e1a1-37c3-41c0-a67b-a23354c6b7b5",
   "metadata": {},
   "source": [
    "# Dietary Restriction AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091265f6-d3fe-4ba5-9d34-dfc963f6b428",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b3ddd4-15fb-4ac8-8bb2-32fabc64f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in ./lib/python3.13/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in ./lib/python3.13/site-packages (from langchain_community) (0.3.47)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in ./lib/python3.13/site-packages (from langchain_community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./lib/python3.13/site-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in ./lib/python3.13/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./lib/python3.13/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./lib/python3.13/site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./lib/python3.13/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./lib/python3.13/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./lib/python3.13/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in ./lib/python3.13/site-packages (from langchain_community) (0.3.18)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./lib/python3.13/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./lib/python3.13/site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in ./lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./lib/python3.13/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.13/site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: anyio in ./lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801761ad-47ed-4c9c-9a4b-6af9e01ccb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93f92c7-ee95-446d-a858-e597259663e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in ./lib/python3.13/site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in ./lib/python3.13/site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64719282-84b7-4436-bd5a-f97f0f48c0bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m f\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import os\n",
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tempfile \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as f\n",
    "from sentence transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70eb509-6c06-4a9a-8b04-9f7e8ab0b747",
   "metadata": {},
   "source": [
    "### Initialize a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0671e03d-62f0-4163-b30d-416cd736952d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/30 13:18:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Local Spark\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d449c04-4af1-4a23-9f32-cd5d3f71d46d",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "In order to be compatible with LLM that we will be creating, the data needs to be processed to be in an efficient retrieval format and stored in a searchable index. \n",
    "\n",
    "##### Recipe Data\n",
    "Our recipe data is sourced from web-scraped data containing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ca3b909-a451-4be2-afe3-81c23be6c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 14:29:56 WARN TaskSetManager: Stage 16 contains a task of very large size (16301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               title|         ingredients|        instructions|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|  Baked Greens Chips|[6 to 8 ounces he...|Watch how to make...|\n",
      "|Sweet Potato-Chic...|[2 large sweet po...|To prepare the ha...|\n",
      "|         Cali Burger|[1/4 cup mayonnai...|For the chipotle ...|\n",
      "|Oatmeal Cream Che...|[2 sticks unsalte...|Preheat the oven ...|\n",
      "|    Campari Spritzer|[1 (12-ounce) can...|Stir the orange j...|\n",
      "|Seared Rack of La...|[1/2 cup pistachi...|Watch how to make...|\n",
      "|         Cream Puffs|[6 tablespoons un...|Special equipment...|\n",
      "|Italian Style Hot...|[Cooking oil, sui...|In a saucepan ove...|\n",
      "|    Crab Cakes Salad|[2 tablespoons fi...|For the salad: Co...|\n",
      "|      Hot Cross Buns|[2 ounces fresh y...|Crumble the yeast...|\n",
      "|Strawberries with...|[4 pints (8 cups)...|Thirty minutes to...|\n",
      "|       Curry Chicken|[2 pounds chicken...|Put the sliced ch...|\n",
      "|Golden Squash Blo...|[1 1/2 tablespoon...|The broth: In a 4...|\n",
      "|Mexican Hot Choco...|[4 cups whole mil...|For the base: Add...|\n",
      "|Georgian Short Ri...|[5 pounds cross c...|In a heavy casser...|\n",
      "|    Chicken Milanese|[1 pound thin-cut...|Marinate the chic...|\n",
      "|Citrus Marinated ...|[1 pound large gr...|Drain the olives ...|\n",
      "|Beet-and-Potato L...|[2 medium russet ...|Preheat the oven ...|\n",
      "|Green Tea and Gin...|[3 cups water, 1/...|Bring a tea kettl...|\n",
      "|Jalapeno Cheese B...|                  []|Mix 2 tablespoons...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_files = os.listdir(\"./\")\n",
    "recipe_files = [file for file in all_files if \"recipes_raw_nosource\" in file]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file_name in recipe_files: \n",
    "    temp_path = os.path.join(tempfile.gettempdir(), file_name)\n",
    "    \n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    file_df = pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "    df_list.append(file_df)  # Collect DataFrame\n",
    "    \n",
    "# Concatenate all dataframes\n",
    "recipes_df = pd.concat(df_list)\n",
    "\n",
    "# select only title, ingredient, instructions columns\n",
    "recipes_df = recipes_df[['title', 'ingredients', 'instructions']]\n",
    "\n",
    "# repartition the dataframe \n",
    "recipes_df = spark.createDataFrame(recipes_df)\n",
    "recipes_df = recipes_df.repartition(100)\n",
    "\n",
    "recipes_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065e566-2a43-4653-acd5-7429d1fb50fe",
   "metadata": {},
   "source": [
    "##### Cooking Literature Data\n",
    "\n",
    "The cooking literature data was pre-processed from PDF text files into a usable format in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d99911c-51dd-453a-b595-da19760fae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|           file_name|            metadata|            chunk_id|                body|tables|\n",
      "+--------------------+--------------------+--------------------+--------------------+------+\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# HIVAICES I # FO...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# ADVANCES IN FOO...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|     NO_CONTENT_HERE|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# ADVANCES IN FOO...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# CRC Press # Tay...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|en made to publis...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|. Except as permi...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|nter, Inc. (CCC),...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|.taylorandfrancis...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# Contents # Fore...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|....................|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...| Labropoulos, and...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|i, and Pietro Cat...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# Contents # Chap...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|, and Athanasios ...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|# Foreword Knowle...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...| transport of foo...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|and safety. Howev...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|ion of the impact...|    []|\n",
      "|ADVANCES_IN_FOOD_...|{date -> NULL, ti...|ADVANCES_IN_FOOD_...|ncluding the use ...|    []|\n",
      "+--------------------+--------------------+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 13:34:45 WARN TaskSetManager: Stage 8 contains a task of very large size (1335 KiB). The maximum recommended task size is 1000 KiB.\n",
      "Exception ignored in: <_io.BufferedWriter name=5>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jenny/ollama-env/lib/python3.13/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 193, in manager\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "cook_lit_files = [file for file in all_files if \"chunked_data\" in file]\n",
    "\n",
    "cook_lit_df = pd.read_json(cook_lit_files[0])\n",
    "cook_lit_df = spark.createDataFrame(cook_lit_df)\n",
    "cook_lit_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15442b-7d8e-4f5c-ab55-a34f30c72a64",
   "metadata": {},
   "source": [
    "### Data Chunking\n",
    "##### Recipes Data\n",
    "The data was chunked into recipe-level chunks, since the recipes will then be able toi be referenced individually when needed. Since this use case is about modifying recipes in their entirety, we want the model to be able to reference the recipes in their entirety during its retrieval process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9aa94e8-41ca-494c-b854-f093833a0c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/30 14:49:10 WARN TaskSetManager: Stage 28 contains a task of very large size (16301 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|               title|         ingredients|        instructions|          chunk_text|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|  Baked Greens Chips|[6 to 8 ounces he...|Watch how to make...|Baked Greens Chip...|\n",
      "|Sweet Potato-Chic...|[2 large sweet po...|To prepare the ha...|Sweet Potato-Chic...|\n",
      "|         Cali Burger|[1/4 cup mayonnai...|For the chipotle ...|Cali Burger\\n1/4 ...|\n",
      "|Oatmeal Cream Che...|[2 sticks unsalte...|Preheat the oven ...|Oatmeal Cream Che...|\n",
      "|    Campari Spritzer|[1 (12-ounce) can...|Stir the orange j...|Campari Spritzer\\...|\n",
      "|Seared Rack of La...|[1/2 cup pistachi...|Watch how to make...|Seared Rack of La...|\n",
      "|         Cream Puffs|[6 tablespoons un...|Special equipment...|Cream Puffs\\n6 ta...|\n",
      "|Italian Style Hot...|[Cooking oil, sui...|In a saucepan ove...|Italian Style Hot...|\n",
      "|    Crab Cakes Salad|[2 tablespoons fi...|For the salad: Co...|Crab Cakes Salad\\...|\n",
      "|      Hot Cross Buns|[2 ounces fresh y...|Crumble the yeast...|Hot Cross Buns\\n2...|\n",
      "|Strawberries with...|[4 pints (8 cups)...|Thirty minutes to...|Strawberries with...|\n",
      "|       Curry Chicken|[2 pounds chicken...|Put the sliced ch...|Curry Chicken\\n2 ...|\n",
      "|Golden Squash Blo...|[1 1/2 tablespoon...|The broth: In a 4...|Golden Squash Blo...|\n",
      "|Mexican Hot Choco...|[4 cups whole mil...|For the base: Add...|Mexican Hot Choco...|\n",
      "|Georgian Short Ri...|[5 pounds cross c...|In a heavy casser...|Georgian Short Ri...|\n",
      "|    Chicken Milanese|[1 pound thin-cut...|Marinate the chic...|Chicken Milanese\\...|\n",
      "|Citrus Marinated ...|[1 pound large gr...|Drain the olives ...|Citrus Marinated ...|\n",
      "|Beet-and-Potato L...|[2 medium russet ...|Preheat the oven ...|Beet-and-Potato L...|\n",
      "|Green Tea and Gin...|[3 cups water, 1/...|Bring a tea kettl...|Green Tea and Gin...|\n",
      "|Jalapeno Cheese B...|                  []|Mix 2 tablespoons...|Jalapeno Cheese B...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recipes_df_chunk = recipes_df.withColumn(\"chunk_text\", \n",
    "                                         f.concat_ws(\"\\n\", f.col(\"title\"), f.col(\"ingredients\"), f.col(\"instructions\")))\n",
    "recipes_df_chunk.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8c3b9",
   "metadata": {},
   "source": [
    "### Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and generate embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = np.array([embedding_model.encode(chunk[\"body\"]) for chunk in chunked_data], dtype=np.float32)\n",
    "\n",
    "# Store embeddings in chunked JSON\n",
    "for i, chunk in enumerate(chunked_data):\n",
    "    chunk[\"embedding\"] = embeddings[i].tolist()\n",
    "    \n",
    "# Create and save FAISS index\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8452bd-d0d9-4992-9c91-37e1ca09f1dd",
   "metadata": {},
   "source": [
    "### Model Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf308122-2a1b-4b1c-9b61-f06468801082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2l/vxt6rlxn46s5z8qm6j10lrg00000gp/T/ipykernel_6927/4125328510.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama3.2\")\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2\")\n",
    "print(\"Loaded Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc90ea-a8d9-423b-8d61-bbf6789dcde0",
   "metadata": {},
   "source": [
    "##### Prompt Engineering\n",
    "The prompt inputted by the user should only need to contain the necessary recipe that the user wants to modify. The following prompt engineering code adds additional, consistent language that does the following: \n",
    "- Specifies that the user wants to modify the recipe, retaining the original intention\n",
    "- Provides the dietary framework to stick to, in this case the high-protein low-carb diet. In another phase of development, this could be changed to xspecify a diet of choice\n",
    "- Requests a list of macronutrients based on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87cf625c-bc74-48f6-a035-23f37b1a4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To modify the pancake recipe to suit a high-protein, low-carb diet, we'll make some key changes:\n",
      "\n",
      "1. Replace all-purpose flour with an almond flour-based mixture: Almond flour is a good source of protein and has a lower carb content compared to traditional flour.\n",
      "2. Use protein-rich milk alternative: We'll replace regular milk with unsweetened almond milk or another low-carb milk alternative, such as coconut milk.\n",
      "3. Add more protein-rich ingredients: Introduce some protein powder (e.g., whey or pea) to boost the protein content of each pancake.\n",
      "\n",
      "Here's the modified recipe:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 ½ cups almond flour\n",
      "* 3 ½ teaspoons baking powder (make sure it's sugar-free)\n",
      "* 1 tablespoon coconut sugar (or another low-carb sweetener)\n",
      "* ¼ teaspoon salt\n",
      "* 1/4 cup protein powder (whey or pea-based)\n",
      "* 1 ¼ cups unsweetened almond milk\n",
      "* 3 tablespoons melted butter\n",
      "* 1 large egg\n",
      "\n",
      "Directions:\n",
      "\n",
      "1. Sift the almond flour, baking powder, coconut sugar, and salt together in a large bowl.\n",
      "2. Make a well in the center of the mixture and add the protein powder, almond milk, and melted butter; mix until smooth.\n",
      "3. Add the egg to the mixture and mix until combined.\n",
      "4. Heat a lightly oiled griddle or pan over medium-high heat.\n",
      "5. Pour or scoop the batter onto the griddle using approximately 1/4 cup for each pancake; cook until bubbles form and the edges are dry, about 2 to 3 minutes.\n",
      "6. Flip and cook until browned on the other side.\n",
      "\n",
      "Analysis:\n",
      "\n",
      "Per serving (assuming 8-10 pancakes):\n",
      "\n",
      "* Calories: 220-250\n",
      "* Protein: 30-35 grams (depending on protein powder used)\n",
      "* Fat: 12-15g\n",
      "* Carbohydrates: 5-7g (mostly from almond flour and natural sweeteners)\n",
      "* Fiber: 2-3g\n",
      "\n",
      "Note: The macronutrient analysis is an estimate, as the exact values will depend on the specific ingredients and portion sizes used.\n",
      "\n",
      "This modified recipe should provide a good balance of protein, healthy fats, and low-carb carbohydrates, making it suitable for a high-protein, low-carb diet. However, be sure to consult with a healthcare professional or registered dietitian before making significant changes to your diet.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c2fb7ec-044c-477d-b71e-5ef7c8238621",
   "metadata": {},
   "source": [
    "##### RAG Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce41e0-6055-4f64-812a-c6355bf2c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(query, k=5):\n",
    "    \"\"\"Retrieve top-k most relevant chunks using FAISS.\"\"\"\n",
    "    query_embedding = embedding_model.encode(query).reshape(1, -1)  # Convert query to embedding\n",
    "    distances, indices = index.search(query_embedding, k)  # Retrieve top-k chunks\n",
    "\n",
    "    return [chunked_data[i] for i in indices[0]]  # Get original text chunks\n",
    "\n",
    "def query_ollama_with_context(query):\n",
    "    \"\"\"Retrieve relevant context and query Ollama 3.2.\"\"\"\n",
    "    retrieved_chunks = retrieve_relevant_chunks(query)\n",
    "    context = \"\\n\".join([chunk[\"body\"] for chunk in retrieved_chunks])  # Combine relevant chunks\n",
    "\n",
    "    # Formulate prompt for LLaMA\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "\n",
    "    # Query Ollama\n",
    "    response = ollama.chat(model=\"llama3\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = input(\"Enter your recipe: \")\n",
    "    query += \" Modify this recipe so that it is more suited for a high-protein, low carb diet. Provide a list of macronutrients as a part of the analysis.\n",
    "    answer = query_ollama_with_context(query)\n",
    "    print(\"\\nOllama's Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e5d71",
   "metadata": {},
   "source": [
    "### Recipe Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21536093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does Not Meet Criteria\n"
     ]
    }
   ],
   "source": [
    "def evaluate_recipe(protein_g, fat_g, carb_g):\n",
    "    # Caloric values per gram\n",
    "    PROTEIN_CAL = 4\n",
    "    CARB_CAL = 4\n",
    "    FAT_CAL = 9\n",
    "    \n",
    "    # Calculate total calories\n",
    "    total_calories = (protein_g * PROTEIN_CAL) + (fat_g * FAT_CAL) + (carb_g * CARB_CAL)\n",
    "    \n",
    "    if total_calories == 0:\n",
    "        return \"Invalid recipe: Total calories cannot be zero.\"\n",
    "    \n",
    "    # Calculate macronutrient percentage\n",
    "    protein_pct = (protein_g * PROTEIN_CAL / total_calories) * 100\n",
    "    fat_pct = (fat_g * FAT_CAL / total_calories) * 100\n",
    "    carb_pct = (carb_g * CARB_CAL / total_calories) * 100\n",
    "    \n",
    "    # Define healthy ranges\n",
    "    protein_range = (10, 30)\n",
    "    fat_range = (20, 35)\n",
    "    carb_range = (45, 65)\n",
    "    \n",
    "    # Check if recipe meets healthy criteria\n",
    "    if (protein_range[0] <= protein_pct <= protein_range[1] and\n",
    "        fat_range[0] <= fat_pct <= fat_range[1] and\n",
    "        carb_range[0] <= carb_pct <= carb_range[1]):\n",
    "        return \"Meets Criteria\"\n",
    "    else:\n",
    "        return \"Does Not Meet Criteria\"\n",
    "# Example usage\n",
    "recipe_result = evaluate_recipe(protein_g=3, fat_g=20, carb_g=100)\n",
    "print(recipe_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a651f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
